# -*- coding: utf-8 -*-
"""Sentiment Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pPvMdWMWA0FeZjbX2wdvaARNkIJz80oM

**Sentiment Analysis**
"""

import pandas as pd
import re
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# Load dataset
df = pd.read_csv("Twitter_Data.csv")

# Assuming the column containing the text data is named 'clean_text'
text_column_name = "clean_text"

# Function to clean text
def clean_text(text):
    text = re.sub(r'http\S+', '', text)  # Remove URLs
    text = re.sub(r'@\w+', '', text)  # Remove mentions
    text = re.sub(r'#\w+', '', text)  # Remove hashtags
    text = re.sub(r'\s+', ' ', text)  # Remove extra spaces
    return text.strip()

# Apply text cleaning
df["cleaned_text"] = df[text_column_name].astype(str).apply(clean_text)

# Initialize Sentiment Analyzer
analyzer = SentimentIntensityAnalyzer()

# Define a dictionary to store emoji sentiments
emoji_sentiment = {
    "ðŸ”¥": 0.5,   # Adjusted sentiment weight
    "ðŸ’–": 0.5,
    "ðŸš€": 0.4,
    "ðŸ˜ƒ": 0.3,
    "ðŸ’ª": 0.3,
    "ðŸ’€": -0.4,
    "ðŸ¤¬": -0.5,
    "ðŸ‘Ž": -0.3,
    "ðŸ’”": -0.3,
    "ðŸ˜¡": -0.3,
    "ðŸ˜": 0.0,   # Neutral
    "ðŸ¤”": 0.0,
    "ðŸ¤·â€â™‚ï¸": 0.0
}

# Function to get sentiment
def get_sentiment(text):
    score = analyzer.polarity_scores(text)["compound"]

    # Check for emojis and adjust score
    for emoji, sentiment_score in emoji_sentiment.items():
        if emoji in text:
            score += sentiment_score

    print(f"Text: {text} | Score: {score}")  # Debugging output

    # Adjusted thresholds for better Neutral detection
    if score > 0.2:
        return "Positive"
    elif score < -0.2:
        return "Negative"
    else:
        return "Neutral"

# Apply sentiment analysis to all tweets
df["Sentiment"] = df["cleaned_text"].apply(get_sentiment)

# Display sentiment counts
print(df["Sentiment"].value_counts())

# Visualize sentiment distribution
plt.figure(figsize=(8, 6))
df["Sentiment"].value_counts().plot(kind="bar", color=["green", "red", "gray"])
plt.title("Sentiment Distribution")
plt.xlabel("Sentiment")
plt.ylabel("Count")
plt.show()

# Generate Word Cloud for positive tweets
positive_text = " ".join(df[df["Sentiment"] == "Positive"]["cleaned_text"])
wordcloud = WordCloud(width=800, height=400, background_color="white").generate(positive_text)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.title("Positive Sentiment Word Cloud")
print("\n")
plt.show()

# **Predict sentiment for multiple user inputs**
print("\nEnter multiple tweets (one per line). Type 'exit' on a new line to finish:\n")
user_inputs = []
while True:
    user_text = input()
    if user_text.lower() == "exit":
        break
    user_inputs.append(user_text)

# Process and analyze sentiments for all inputs
if user_inputs:
    cleaned_inputs = [clean_text(text) for text in user_inputs]
    sentiments = [get_sentiment(text) for text in cleaned_inputs]

    print("\nPredicted Sentiments:")
    for text, sentiment in zip(user_inputs, sentiments):
        print(f"Tweet: {text}\nSentiment: {sentiment}\n")